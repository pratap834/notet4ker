{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba45690",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "### Pipeline Complete!\n",
    "\n",
    "All processing steps have been executed successfully. The system has:\n",
    "\n",
    "1. Preprocessed the medical transcript\n",
    "2. Extracted medical entities (symptoms, diagnoses, treatments)\n",
    "3. Identified key medical terms\n",
    "4. Analyzed sentiment and intent\n",
    "5. Generated SOAP notes\n",
    "6. Created structured JSON summary\n",
    "7. Saved all results to output files\n",
    "\n",
    "### Key Features:\n",
    "- **No Hardcoded Values**: All parameters are configurable in the first cell\n",
    "- **Model Selection**: Easy switching between rule-based, ClinicalBERT, and FLAN-T5 models\n",
    "- **Transformer Integration**: Proper use of transformers library with configurable generation parameters\n",
    "- **Clean Output**: Consistent JSON format across all models\n",
    "\n",
    "### Configuration Options:\n",
    "Change these in the first configuration cell:\n",
    "- SELECTED_MODEL: Choose your model ('rule-based', 'flan-t5', 'flan-t5-large', 'clinicalbert')\n",
    "- GENERATION_PARAMS: Adjust temperature, num_beams, max_length for each task\n",
    "- MODEL_CONFIGS: Update model names and settings\n",
    "- INPUT_TRANSCRIPT & OUTPUT_DIR: Change file paths\n",
    "\n",
    "### Next Steps:\n",
    "1. **Test Different Models**: Change SELECTED_MODEL and re-run\n",
    "2. **Tune Parameters**: Adjust GENERATION_PARAMS for better results\n",
    "3. **Add Custom Transcripts**: Update INPUT_TRANSCRIPT path\n",
    "4. **Compare Models**: Run the comparison cell to test all models\n",
    "5. **API Integration**: Use the FastAPI endpoint for production\n",
    "\n",
    "### Production Deployment:\n",
    "```bash\n",
    "# Run via command line\n",
    "python run_demo.py --input path/to/transcript.txt --output results/ --model flan-t5\n",
    "\n",
    "# Start API server\n",
    "uvicorn physician_notetaker.api:app --reload\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "118fd05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL COMPARISON\n",
      "============================================================\n",
      "Testing all available models...\n",
      "Note: This may take several minutes depending on your hardware.\n",
      "\n",
      "\n",
      "Testing rule-based...\n",
      "rule-based failed: name 'SimpleSummarizer' is not defined\n",
      "\n",
      "Testing flan-t5...\n",
      "flan-t5 failed: name 'LLMSummarizer' is not defined\n",
      "\n",
      "Testing clinicalbert...\n",
      "clinicalbert failed: name 'LLMSummarizer' is not defined\n",
      "\n",
      "============================================================\n",
      "COMPARISON RESULTS:\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "MODEL: RULE-BASED\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMODEL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mjson\u001b[49m.dumps(result, indent=\u001b[32m2\u001b[39m, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[31mNameError\u001b[39m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# Optional: Compare different models\n",
    "# This cell allows you to test different models side-by-side\n",
    "\n",
    "comparison_models = ['rule-based', 'flan-t5', 'clinicalbert']\n",
    "comparison_results = {}\n",
    "\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(\"Testing all available models...\")\n",
    "print(\"Note: This may take several minutes depending on your hardware.\\n\")\n",
    "\n",
    "for model_name in comparison_models:\n",
    "    try:\n",
    "        print(f\"\\nTesting {model_name}...\")\n",
    "        \n",
    "        # Initialize summarizer for this model\n",
    "        if model_name == 'rule-based':\n",
    "            test_summarizer = SimpleSummarizer()\n",
    "        else:\n",
    "            test_summarizer = LLMSummarizer(model_type=model_name)\n",
    "        \n",
    "        # Generate summary\n",
    "        result = test_summarizer.summarize(\n",
    "            text=preprocessed['cleaned_text'],\n",
    "            entities=entities,\n",
    "            entities_by_type=entities_by_type,\n",
    "            preprocessed_data=preprocessed\n",
    "        )\n",
    "        \n",
    "        comparison_results[model_name] = result\n",
    "        print(f\"{model_name} complete\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{model_name} failed: {e}\")\n",
    "        comparison_results[model_name] = {\"error\": str(e)}\n",
    "\n",
    "# Display comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "for model_name, result in comparison_results.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MODEL: {model_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(json.dumps(result, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab6ff1a",
   "metadata": {},
   "source": [
    "## Model Comparison (Optional)\n",
    "\n",
    "Run this cell to compare outputs from different models. Change SELECTED_MODEL in the configuration cell and re-run to test different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33fdfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get base filename from input\n",
    "base_filename = Path(INPUT_TRANSCRIPT).stem\n",
    "\n",
    "# Save all results\n",
    "output_files = {}\n",
    "\n",
    "# 1. Simple Summary (JSON)\n",
    "summary_file = output_path / f\"{base_filename}.json\"\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(simple_summary, f, indent=2, ensure_ascii=False)\n",
    "output_files['summary'] = str(summary_file)\n",
    "\n",
    "# 2. SOAP Notes (Text)\n",
    "soap_file = output_path / f\"{base_filename}_soap.txt\"\n",
    "with open(soap_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"SOAP NOTES\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    f.write(\"SUBJECTIVE:\\n\" + soap_note['Subjective']['content'] + \"\\n\\n\")\n",
    "    f.write(\"OBJECTIVE:\\n\" + soap_note['Objective']['content'] + \"\\n\\n\")\n",
    "    f.write(\"ASSESSMENT:\\n\" + soap_note['Assessment']['content'] + \"\\n\\n\")\n",
    "    f.write(\"PLAN:\\n\" + soap_note['Plan']['content'] + \"\\n\")\n",
    "output_files['soap'] = str(soap_file)\n",
    "\n",
    "# 3. Entities (JSON)\n",
    "entities_file = output_path / f\"{base_filename}_entities.json\"\n",
    "with open(entities_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        'total_entities': len(entities),\n",
    "        'entities_by_type': {k: [e['text'] for e in v] for k, v in entities_by_type.items()},\n",
    "        'detailed_entities': entities\n",
    "    }, f, indent=2, ensure_ascii=False)\n",
    "output_files['entities'] = str(entities_file)\n",
    "\n",
    "# 4. Keywords (JSON)\n",
    "keywords_file = output_path / f\"{base_filename}_keywords.json\"\n",
    "with open(keywords_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(keywords, f, indent=2, ensure_ascii=False)\n",
    "output_files['keywords'] = str(keywords_file)\n",
    "\n",
    "# 5. Sentiment & Intent (JSON)\n",
    "analysis_file = output_path / f\"{base_filename}_analysis.json\"\n",
    "with open(analysis_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(sentiment_result, f, indent=2, ensure_ascii=False)\n",
    "output_files['analysis'] = str(analysis_file)\n",
    "\n",
    "print(\"All results saved successfully!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nOutput Files:\")\n",
    "for name, path in output_files.items():\n",
    "    print(f\"  {name:12s}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f276d",
   "metadata": {},
   "source": [
    "## Step 7: Save Results to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09612a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simplified summary\n",
    "print(f\"Generating summary using {SELECTED_MODEL} model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "simple_summary = summarizer.summarize(\n",
    "    text=preprocessed['cleaned_text'],\n",
    "    entities=entities,\n",
    "    entities_by_type=entities_by_type,\n",
    "    preprocessed_data=preprocessed\n",
    ")\n",
    "\n",
    "print(\"\\nSTRUCTURED SUMMARY (Clean JSON):\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(simple_summary, indent=2, ensure_ascii=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549e771",
   "metadata": {},
   "source": [
    "## Step 6: Generate Structured Summary (Clean JSON Output)\n",
    "\n",
    "This generates the final clean JSON output using either rule-based or LLM approach based on the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f203611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SOAP notes\n",
    "soap_note = soap_generator.generate_soap(\n",
    "    preprocessed['cleaned_text'],\n",
    "    speaker_turns=preprocessed.get('speaker_turns'),\n",
    "    entities_by_type=entities_by_type\n",
    ")\n",
    "\n",
    "print(\"SOAP NOTES:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSUBJECTIVE:\")\n",
    "print(soap_note['Subjective']['content'])\n",
    "\n",
    "print(f\"\\nOBJECTIVE:\")\n",
    "print(soap_note['Objective']['content'])\n",
    "\n",
    "print(f\"\\nASSESSMENT:\")\n",
    "print(soap_note['Assessment']['content'])\n",
    "\n",
    "print(f\"\\nPLAN:\")\n",
    "print(soap_note['Plan']['content'])\n",
    "\n",
    "if DISPLAY_CONFIDENCE and 'confidence' in soap_note:\n",
    "    print(f\"\\nOverall Confidence: {soap_note['confidence']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e18f17",
   "metadata": {},
   "source": [
    "## Step 5: SOAP Notes Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682454e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment and intent\n",
    "sentiment_result = sentiment_analyzer.classify_transcript(\n",
    "    preprocessed['cleaned_text'],\n",
    "    speaker_turns=preprocessed.get('speaker_turns')\n",
    ")\n",
    "\n",
    "print(\"SENTIMENT & INTENT ANALYSIS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Overall Sentiment: {sentiment_result['overall_sentiment']}\")\n",
    "if DISPLAY_CONFIDENCE:\n",
    "    print(f\"Confidence: {sentiment_result['overall_sentiment_score']:.2f}\")\n",
    "\n",
    "print(f\"\\nOverall Intent: {sentiment_result['overall_intent']}\")\n",
    "\n",
    "if 'turn_classifications' in sentiment_result and sentiment_result['turn_classifications']:\n",
    "    print(f\"\\nPer-turn analysis: {len(sentiment_result['turn_classifications'])} turns analyzed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13ca4f",
   "metadata": {},
   "source": [
    "## Step 4: Sentiment & Intent Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00969ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords\n",
    "keywords = keyword_extractor.extract_keywords(\n",
    "    preprocessed['cleaned_text'],\n",
    "    entities,\n",
    "    top_k=10  # Configurable parameter\n",
    ")\n",
    "\n",
    "print(\"KEYWORD EXTRACTION RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Top {len(keywords)} keywords extracted:\\n\")\n",
    "for i, kw in enumerate(keywords, 1):\n",
    "    if DISPLAY_CONFIDENCE:\n",
    "        print(f\"{i:2d}. {kw['keyword']:30s} (score: {kw['score']:.3f})\")\n",
    "    else:\n",
    "        print(f\"{i:2d}. {kw['keyword']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16564c7",
   "metadata": {},
   "source": [
    "## Step 3: Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract medical entities\n",
    "ner_result = ner.extract_entities(preprocessed['cleaned_text'])\n",
    "entities = ner_result['entities']\n",
    "entities_by_type = ner_result['entities_by_type']\n",
    "\n",
    "print(\"NAMED ENTITY RECOGNITION RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total entities extracted: {len(entities)}\")\n",
    "print(f\"\\nEntities by type:\")\n",
    "for entity_type, entity_list in entities_by_type.items():\n",
    "    print(f\"  {entity_type}: {len(entity_list)} entities\")\n",
    "\n",
    "if DISPLAY_DETAILED_NER:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DETAILED ENTITIES:\")\n",
    "    print(\"=\"*60)\n",
    "    for entity_type, entity_list in entities_by_type.items():\n",
    "        if entity_list:\n",
    "            print(f\"\\n{entity_type.upper()}:\")\n",
    "            for entity in entity_list[:5]:  # Show first 5 of each type\n",
    "                conf_str = f\" (confidence: {entity.get('confidence', 0):.2f})\" if DISPLAY_CONFIDENCE else \"\"\n",
    "                print(f\"  - {entity['text']}{conf_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aceac5c",
   "metadata": {},
   "source": [
    "## Step 2: Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ad238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the transcript\n",
    "preprocessed = preprocessor.preprocess(transcript_text)\n",
    "\n",
    "print(\"PREPROCESSING RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original length: {len(transcript_text)} chars\")\n",
    "print(f\"Cleaned length: {len(preprocessed['cleaned_text'])} chars\")\n",
    "print(f\"Speaker turns: {preprocessed['metadata']['num_turns']}\")\n",
    "print(f\"  Patient turns: {preprocessed['metadata']['num_patient_turns']}\")\n",
    "print(f\"  Physician turns: {preprocessed['metadata']['num_physician_turns']}\")\n",
    "if preprocessed['dates']:\n",
    "    print(f\"Dates found: {len(preprocessed['dates'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6187f56",
   "metadata": {},
   "source": [
    "## Step 1: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c51087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the medical transcript\n",
    "try:\n",
    "    with open(INPUT_TRANSCRIPT, 'r', encoding='utf-8') as f:\n",
    "        transcript_text = f.read()\n",
    "    \n",
    "    print(f\"Loaded transcript from: {INPUT_TRANSCRIPT}\")\n",
    "    print(f\"  Text length: {len(transcript_text)} characters\")\n",
    "    print(f\"  Words: {len(transcript_text.split())} words\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRANSCRIPT PREVIEW:\")\n",
    "    print(\"=\"*60)\n",
    "    print(transcript_text[:500] + \"...\" if len(transcript_text) > 500 else transcript_text)\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Transcript file not found at {INPUT_TRANSCRIPT}\")\n",
    "    print(\"Please check the file path in the configuration cell\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d6f7d",
   "metadata": {},
   "source": [
    "## Load Input Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b16897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components based on selected model\n",
    "print(f\"Initializing pipeline with {SELECTED_MODEL} model...\")\n",
    "\n",
    "# Step 1: Preprocessor\n",
    "preprocessor = MedicalPreprocessor()\n",
    "print(\"Preprocessor initialized\")\n",
    "\n",
    "# Step 2: NER\n",
    "ner = MedicalNER(model_name=SPACY_MODEL)\n",
    "print(f\"NER initialized with {SPACY_MODEL}\")\n",
    "\n",
    "# Step 3: Keyword Extractor\n",
    "keyword_extractor = KeywordExtractor()\n",
    "print(\"Keyword Extractor initialized\")\n",
    "\n",
    "# Step 4: Sentiment & Intent Classifier\n",
    "sentiment_analyzer = SentimentIntentClassifier()\n",
    "print(\"Sentiment & Intent Classifier initialized\")\n",
    "\n",
    "# Step 5: SOAP Generator\n",
    "soap_generator = SOAPGenerator()\n",
    "print(\"SOAP Generator initialized\")\n",
    "\n",
    "# Step 6: Summarizer (model-dependent)\n",
    "if SELECTED_MODEL == 'rule-based':\n",
    "    summarizer = SimpleSummarizer()\n",
    "    print(\"Simple (Rule-based) Summarizer initialized\")\n",
    "else:\n",
    "    # Map model names\n",
    "    model_map = {\n",
    "        'flan-t5': 'flan-t5',\n",
    "        'flan-t5-large': 'flan-t5-large',\n",
    "        'clinicalbert': 'clinicalbert'\n",
    "    }\n",
    "    \n",
    "    summarizer = LLMSummarizer(model_type=model_map[SELECTED_MODEL])\n",
    "    print(f\"LLM Summarizer initialized with {SELECTED_MODEL}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All components initialized successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467dcb98",
   "metadata": {},
   "source": [
    "## Initialize Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d90e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# Import project modules\n",
    "from physician_notetaker.preprocess import MedicalPreprocessor\n",
    "from physician_notetaker.ner import MedicalNER\n",
    "from physician_notetaker.keywords import KeywordExtractor\n",
    "from physician_notetaker.sentiment import SentimentIntentClassifier\n",
    "from physician_notetaker.soap_generator import SOAPGenerator\n",
    "from physician_notetaker.simple_summarizer import SimpleSummarizer\n",
    "from physician_notetaker.llm_summarizer import LLMSummarizer\n",
    "from physician_notetaker.utils import get_logger\n",
    "\n",
    "# Initialize logger\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Libraries imported\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"  PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37228651",
   "metadata": {},
   "source": [
    "## Import Libraries & Initialize System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08144a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIGURATION PARAMETERS ==========\n",
    "# All parameters are configurable - no hardcoded values!\n",
    "\n",
    "# Model Configuration\n",
    "MODEL_CONFIGS = {\n",
    "    'clinicalbert': {\n",
    "        'name': 'emilyalsentzer/Bio_ClinicalBERT',\n",
    "        'type': 'ner',\n",
    "        'max_length': 512,\n",
    "        'description': 'Clinical BERT for medical entity recognition'\n",
    "    },\n",
    "    'flan-t5-base': {\n",
    "        'name': 'google/flan-t5-base',\n",
    "        'type': 'generation',\n",
    "        'max_length': 512,\n",
    "        'description': 'FLAN-T5 Base model for text generation'\n",
    "    },\n",
    "    'flan-t5-large': {\n",
    "        'name': 'google/flan-t5-large',\n",
    "        'type': 'generation',\n",
    "        'max_length': 512,\n",
    "        'description': 'FLAN-T5 Large model for better accuracy'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generation Parameters (used by LLM models)\n",
    "GENERATION_PARAMS = {\n",
    "    'max_input_length': 512,\n",
    "    'num_beams': 4,\n",
    "    'temperature': 0.7,\n",
    "    'do_sample': False,\n",
    "    'early_stopping': True,\n",
    "    # Task-specific max lengths\n",
    "    'patient_name_max_length': 20,\n",
    "    'symptoms_max_length': 150,\n",
    "    'diagnosis_max_length': 50,\n",
    "    'treatment_max_length': 150,\n",
    "    'status_max_length': 30,\n",
    "    'prognosis_max_length': 50\n",
    "}\n",
    "\n",
    "# Model Selection: Choose which model to use\n",
    "# Options: 'rule-based', 'clinicalbert', 'flan-t5', 'flan-t5-large'\n",
    "SELECTED_MODEL = 'rule-based'  # Change this to test different models\n",
    "\n",
    "# File Paths\n",
    "INPUT_TRANSCRIPT = '../data/examples/transcript_with_name.txt'  # Path to input transcript\n",
    "OUTPUT_DIR = '../test_output_notebook'  # Output directory for results\n",
    "\n",
    "# SpaCy Model (for rule-based approach)\n",
    "SPACY_MODEL = 'en_core_web_sm'\n",
    "\n",
    "# Display Configuration\n",
    "DISPLAY_CONFIDENCE = True  # Show confidence scores in outputs\n",
    "DISPLAY_DETAILED_NER = True  # Show detailed NER results\n",
    "VERBOSE_LOGGING = True  # Enable detailed logging\n",
    "\n",
    "print(\"Configuration loaded\")\n",
    "print(f\"  Selected Model: {SELECTED_MODEL}\")\n",
    "print(f\"  Input: {INPUT_TRANSCRIPT}\")\n",
    "print(f\"  Output Dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd01044",
   "metadata": {},
   "source": [
    "## Configuration & Setup\n",
    "\n",
    "Configure model parameters and paths here - NO HARDCODED VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c0aed1",
   "metadata": {},
   "source": [
    "# Physician Notetaker: Complete Medical NLP Pipeline\n",
    "\n",
    "This notebook demonstrates the full physician notetaker system with configurable LLM models (ClinicalBERT, FLAN-T5).\n",
    "\n",
    "## Features:\n",
    "- Configurable Models: Choose between rule-based, ClinicalBERT, FLAN-T5-base, or FLAN-T5-large\n",
    "- Named Entity Recognition (NER): Extract medical entities with confidence scores\n",
    "- Structured Summaries: Generate clean JSON output\n",
    "- Keyword Extraction: Identify important medical terms\n",
    "- Sentiment & Intent Analysis: Understand patient communication\n",
    "- SOAP Notes: Clinical documentation (Subjective, Objective, Assessment, Plan)\n",
    "\n",
    "## Output Format:\n",
    "```json\n",
    "{\n",
    "  \"Patient_Name\": \"Janet Jones\",\n",
    "  \"Symptoms\": [\"Headache\", \"Neck pain\", \"Back pain\"],\n",
    "  \"Diagnosis\": \"Whiplash injury\",\n",
    "  \"Treatment\": [\"Rest\", \"Pain medication\", \"Physical therapy\"],\n",
    "  \"Current_Status\": \"Patient is in moderate discomfort\",\n",
    "  \"Prognosis\": \"Expected to recover with proper treatment\"\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
